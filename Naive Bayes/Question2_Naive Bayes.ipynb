{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Question2_Assignment4.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DLpGX_dAWuhG",
        "outputId": "accff1a6-e3cd-470d-fcbb-f4c79d87d3e6"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vfuO50fgW30H",
        "outputId": "a3111d81-3213-494a-c98f-25ece951013f"
      },
      "source": [
        "#Library to perform operations\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "#Library to perform Naive Bayes\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "\n",
        "#Library to perform train test split\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "#Library to perform PCA\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn import preprocessing \n",
        "#Library to calculate accuracy\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "#Library to load data\n",
        "import re\n",
        "\n",
        "#Library to perform text preprocessing\n",
        "from nltk.corpus import stopwords\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "import string"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nA6x4G_hXe_o"
      },
      "source": [
        "### **Question 2a**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ato683SLXHfN"
      },
      "source": [
        "#Loading the Dataset\n",
        "data = []\n",
        "with open('/content/yelp_labelled.txt') as fh:\n",
        "    for line in fh:\n",
        "      data.append(re.split('\\t|\\n',line))"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b3ZB52i1XM16",
        "outputId": "885f9406-906a-4597-9064-d6e011437921"
      },
      "source": [
        "#Making a dataframe from the loaded data\n",
        "data_2 = pd.DataFrame(data, columns = ['line','label','d'])\n",
        "data_2 = data_2.drop(['d'],axis = 1)\n",
        "print(data_2)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                                                  line label\n",
            "0                             Wow... Loved this place.     1\n",
            "1                                   Crust is not good.     0\n",
            "2            Not tasty and the texture was just nasty.     0\n",
            "3    Stopped by during the late May bank holiday of...     1\n",
            "4    The selection on the menu was great and so wer...     1\n",
            "..                                                 ...   ...\n",
            "995  I think food should have flavor and texture an...     0\n",
            "996                           Appetite instantly gone.     0\n",
            "997  Overall I was not impressed and would not go b...     0\n",
            "998  The whole experience was underwhelming, and I ...     0\n",
            "999  Then, as if I hadn't wasted enough of my life ...     0\n",
            "\n",
            "[1000 rows x 2 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lfnj3VK2XRzn",
        "outputId": "b34bf65a-95cc-4156-a0b4-4ab583f7e4d6"
      },
      "source": [
        "#Splitting the Dataset\n",
        "X_train, X_test, y_train, y_test = train_test_split(data_2['line'], data_2['label'],stratify=data_2['label'], test_size=0.3)\n",
        "print(X_train.shape)\n",
        "print(X_test.shape)\n",
        "print(y_train.shape)\n",
        "print(y_test.shape)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(700,)\n",
            "(300,)\n",
            "(700,)\n",
            "(300,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I3SHXMR-YADI"
      },
      "source": [
        "### **Question 2b**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hVt7vLBKXz1Z"
      },
      "source": [
        "def text_preprocess(message):\n",
        "    #A part\n",
        "    #Checking if the characters are in punctuation\n",
        "    punc_remove = [char for char in message if char not in string.punctuation]\n",
        "    #Forming the String again by joining the letters\n",
        "    punc_remove = ''.join(punc_remove)\n",
        "    #B part\n",
        "    #Making the string to lower case after removing punctuations\n",
        "    lower_str = \"\"\n",
        "    for word in punc_remove.split():\n",
        "      lower_str += word.lower() + \" \"\n",
        "    # lower_str = punc_remove.lower()\n",
        "    #C part\n",
        "    #Removing the Stopwords\n",
        "    for word in lower_str.split():\n",
        "      return [word for word in lower_str.split() if word not in stopwords.words('english')]"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "paRbwBYBiuCZ",
        "outputId": "3620e902-ce12-4c53-8582-76979b82f0ee"
      },
      "source": [
        "#Text Preprocessing the line column\n",
        "X_train = X_train.apply(text_preprocess)\n",
        "X_test = X_test.apply(text_preprocess)\n",
        "print(X_train)\n",
        "print(X_test)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "45           [thing, like, prime, rib, dessert, section]\n",
            "3      [stopped, late, may, bank, holiday, rick, stev...\n",
            "738     [love, decor, chinese, calligraphy, wall, paper]\n",
            "11                                     [would, go, back]\n",
            "612    [chicken, got, definitely, reheated, ok, wedge...\n",
            "                             ...                        \n",
            "10                                     [service, prompt]\n",
            "702           [going, since, 2007, every, meal, awesome]\n",
            "674                             [awesome, service, food]\n",
            "858                       [probably, wont, coming, back]\n",
            "687    [decor, nice, piano, music, soundtrack, pleasant]\n",
            "Name: line, Length: 700, dtype: object\n",
            "107                [ambience, wonderful, music, playing]\n",
            "30     [also, combos, like, burger, fries, beer, 23, ...\n",
            "245    [drinks, took, close, 30, minutes, come, one, ...\n",
            "979    [kept, looking, time, soon, become, 35, minute...\n",
            "707                           [would, recommend, others]\n",
            "                             ...                        \n",
            "927       [also, took, forever, bring, us, check, asked]\n",
            "970    [immediately, said, wanted, talk, manager, wan...\n",
            "973                                  [food, wasnt, good]\n",
            "140                                               [dont]\n",
            "646                                            [mistake]\n",
            "Name: line, Length: 300, dtype: object\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dRt1GH8pm-EC"
      },
      "source": [
        "### **Question 2c**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DvSle9MrnAjC"
      },
      "source": [
        "def get_vocab(X_train):\n",
        "  #Getting the vocabulary of unique words from training data\n",
        "  words_train = []\n",
        "  for i in range(X_train.shape[0]):\n",
        "    for j in range(len(X_train.iloc[i])):\n",
        "      words_train.append(X_train.iloc[i][j])\n",
        "  w_train = set(words_train)\n",
        "  print(\"The number of unique words in Vocabulary are \",len(w_train))\n",
        "  print(\"The vocabulary is\")\n",
        "  print(w_train)\n",
        "  return w_train"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jvUQJKELraVW",
        "outputId": "2c55c8bf-977f-4a80-bf99-256852781a5d"
      },
      "source": [
        "def Question2c(X_train,X_test):\n",
        "  #Getting the vocabulary\n",
        "  w_train = get_vocab(X_train)\n",
        "  #Creating the feature count matrix for train data\n",
        "  matrix_train = [ [ 0 for i in range(len(w_train)) ] for j in range(X_train.shape[0])]\n",
        "  count_feature_train = pd.DataFrame( matrix_train, columns = w_train)\n",
        "  #Increasing the occcurence of words by 1\n",
        "  for i in range(X_train.shape[0]):\n",
        "    for j in range(len(X_train.iloc[i])):\n",
        "      word = X_train.iloc[i][j]\n",
        "      count_feature_train.loc[i][word] += 1\n",
        "  print(\"The count feature of train data\")\n",
        "  print(count_feature_train)\n",
        "\n",
        "  #Creating a feature count matrix for test data\n",
        "  matrix_test = [ [ 0 for i in range(len(w_train)) ] for j in range(X_test.shape[0])]\n",
        "  count_feature_test = pd.DataFrame( matrix_test, columns = w_train)\n",
        "  #Increasing the occcurence of words by 1 if word is present in the test and w_train\n",
        "  for i in range(X_test.shape[0]):\n",
        "    for j in range(len(X_test.iloc[i])):\n",
        "      word = X_test.iloc[i][j]\n",
        "      if word in w_train:\n",
        "        #print(count_feature.loc[i][word])\n",
        "        count_feature_test.loc[i][word] += 1\n",
        "  print(\"The count feature of test data\")\n",
        "  print(count_feature_test) \n",
        "  return count_feature_train,count_feature_test\n",
        "  \n",
        "count_feature_train,count_feature_test = Question2c(X_train,X_test)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The number of unique words in Vocabulary are  1570\n",
            "The vocabulary is\n",
            "{'chinese', 'andddd', '785', 'steak', 'leftover', 'lady', 'cut', 'tastings', 'experience', 'solid', 'continue', 'block', 'ordered', 'elsewhere', 'tasted', 'spices', 'shoots', 'attention', 'atrocious', 'hearts', 'cheese', 'year', 'hours', 'reasonable', 'bit', 'disappointed', 'correction', 'pepperand', 'furthermore', 'flavorless', 'unless', 'flavourful', 'banana', 'orders', 'onion', 'jewel', 'ache', 'subpar', 'fantastic', 'unsatisfying', 'lightly', 'saying', 'particular', 'fill', 'new', 'deal', 'refreshing', 'eyes', 'feels', 'going', 'costcos', 'waaaaaayyyyyyyyyy', 'expanded', 'worlds', 'fillet', 'blown', 'seems', 'thrilled', 'carlys', 'needs', 'unique', 'buffet', 'grill', 'pastry', 'venue', 'flop', 'fs', 'thats', 'smells', 'pumpkin', 'huge', 'casino', 'tasty', 'walked', 'serving', 'giving', 'salsa', 'couldnt', 'cocktail', 'togo', 'rancheros', 'spotty', 'lox', 'refill', '30', 'deeply', 'several', 'chips', 'yaall', 'classics', 'cannot', 'disagree', 'every', 'handmade', 'thus', 'given', 'somehow', '1979', 'charcoal', 'opened', 'watched', 'multiple', 'hunan', 'bland', 'idea', 'movies', 'prime', 'id', 'mushroom', 'pecan', 'accomodate', 'either', 'pace', 'scallop', 'came', 'topic', 'dusted', 'around', 'rated', 'similarly', 'kabuki', 'finally', 'hasnt', 'pasta', 'even', 'experiencing', 'someone', 'insulted', 'sooooo', 'pork', 'gas', 'eat', 'wonderful', 'tucson', 'space', 'prepared', 'chickens', 'liked', 'simple', 'airline', 'flavor', 'petrified', 'looked', 'rare', 'hella', 'quality', 'really', 'saving', 'tigerlilly', 'color', 'unexperienced', 'stayed', 'ha', 'door', 'besides', 'yelpers', 'sergeant', 'terrific', 'inconsiderate', 'reviewer', 'larger', 'homemade', 'handling', 'personable', 'gooodd', 'marrow', 'station', 'forth', 'plus', 'stupid', 'giant', 'poorly', 'find', 'zero', 'dirty', 'ignored', 'mistake', 'liking', 'worth', 'ranch', 'rude', 'may', 'black', 'ice', 'largely', 'gordon', 'watered', 'crust', 'cheesecurds', 'wildly', 'pleased', 'try', 'greek', 'stopped', 'visited', 'refused', 'added', 'albondigas', 'husband', 'presentation', 'almost', 'curry', 'patio', 'street', 'companions', 'metro', 'falling', 'stale', 'people', 'delightful', 'crisp', 'sweet', 'tater', 'jamaican', 'favor', 'couple', 'anything', 'joke', 'favorite', 'slices', 'rubber', 'sewer', 'appalling', 'subway', 'downright', 'final', 'hurry', 'empty', 'burgers', 'sadly', 'polite', 'pita', 'describing', 'huevos', 'hankering', 'seating', 'experienced', 'ones', 'heimer', 'mouth', 'wontons', 'inch', 'packed', 'san', 'order', 'meeverything', 'choose', 'ingredients', 'loudly', 'fair', 'via', 'writing', 'bread', 'mouths', 'foodand', 'dried', 'outdoor', 'unwrapped', 'wedges', 'value', 'something', 'right', 'revisiting', 'turn', 'soundtrack', 'step', 'falafels', 'douchey', 'disappoint', 'closed', '40', 'nachos', 'setting', 'nice', 'mozzarella', 'nicest', 'real', 'raving', 'little', 'crêpe', 'wash', 'thumbs', 'crazy', 'rating', 'tiny', 'gratuity', 'show', 'love', 'store', 'perpared', 'minutes', 'wave', 'bigger', 'milkshake', 'grilled', 'customize', 'later', 'francisco', 'worstannoying', 'decorated', 'breeze', 'ahead', 'started', 'gratitude', 'believe', 'half', 'promise', 'thing', 'thoroughly', 'ten', 'concern', 'soggy', 'salty', 'bitches', 'bits', 'apparently', 'reheated', 'nutshell', 'returning', 'instantly', 'itfriendly', '8', 'lack', 'tragedy', 'foodservice', 'cocktails', 'driving', 'seriously', 'thru', 'apology', 'privileged', 'relleno', 'email', 'spinach', 'parties', 'veganveggie', 'joint', 'apart', 'entrees', 'otto', 'portions', 'hostess', 'bay', 'honest', 'expect', 'checked', '5', 'exquisite', 'north', 'preparing', 'garden', 'dime', 'scottsdale', 'comfortable', 'bird', 'sick', 'baby', 'nobu', 'reasonably', 'sugary', 'shocked', 'bloodiest', 'ill', 'waiting', 'judge', 'coffee', 'get', 'felt', 'car', 'mains', 'job', 'business', 'werent', 'bring', 'sharply', 'wire', 'operation', 'flavorful', 'effort', 'tell', 'third', 'trip', 'son', 'decision', 'satisfied', 'quickly', 'nargile', 'treated', 'fellow', 'chicken', 'living', 'handled', 'regularly', 'oh', 'daughter', 'beef', 'greeted', 'longer', 'cotta', 'bisque', 'buldogis', 'options', 'menu', 'cheap', 'anyway', 'market', 'appetite', 'money', 'chewy', 'pancakes', 'massive', 'part', 'big', 'rib', 'rather', 'capers', 'probably', 'meatballs', 'contained', 'papers', 'tongue', 'bbq', 'dog', 'running', 'summer', 'indicate', 'gringos', 'swung', 'disgraceful', 'unfortunately', 'disaster', 'selections', 'well', 'lovers', 'next', 'mile', 'stay', 'dinner', 'accommodations', 'bite', 'smooth', 'dine', 'itdefinitely', 'point', 'mexican', 'dessert', 'bar', 'freaking', 'brought', 'loves', 'didnt', 'im', 'mom', 'management', 'listed', 'tap', 'suck', 'muffin', '6', 'cold', 'duck', 'struck', 'away', 'folks', 'wife', 'recent', 'sad', 'descriptions', 'imagine', 'relationship', 'toasted', 'marys', 'recommend', 'generous', 'weird', 'since', 'sticks', 'first', 'roll', 'relaxed', 'common', 'opportunity', 'fresh', 'nan', 'anyone', 'likes', 'nothing', 'today', 'total', 'excellent', 'beat', 'water', 'pepper', 'patty', 'else', 'tenders', 'wrapped', 'lover', 'impressive', 'noncustomer', 'similar', 'begin', 'still', 'unbelievable', 'overcooked', 'peanut', 'nasty', 'sides', 'super', 'anyways', 'making', 'underwhelming', 'noca', 'portion', 'number', 'shower', 'yeah', 'maybe', 'pizzas', 'exactly', 'work', 'stir', 'months', 'venture', 'food', 'less', 'ratio', 'friends', 'weak', 'peas', 'panna', 'steaks', 'theyd', 'bloddy', 'asked', 'salads', 'rest', 'anymore', 'claimed', 'pancake', 'mostly', 'soups', 'concept', 'fabulous', 'place', 'diverse', 'break', 'court', 'occasional', 'check', 'meatloaf', 'juries', 'pan', 'sign', 'mixed', 'classic', 'frozen', 'disappointing', 'tip', 'host', 'eyed', 'better', 'meal', 'pricing', 'pictures', 'italian', 'sorely', 'absolutley', 'outta', '1199', 'pulled', 'stars', 'ever', 'tried', 'boiled', 'delicious', 'topvery', 'watch', 'serve', 'talk', 'honestly', 'cool', 'salmon', 'grossed', 'cashier', 'worst', 'take', 'greedy', 'luck', 'time', 'definately', 'waste', 'asking', 'considering', 'group', 'heads', 'slow', 'guests', 'dropped', 'amazingrge', 'handsdown', 'fun', 'lot', 'suggest', 'pop', 'definitely', 'dry', 'climbing', 'barely', 'box', 'look', 'room', 'caterpillar', 'pleasant', 'dollars', 'fucking', 'occasions', 'lighter', 'meals', 'sub', 'sushi', 'performed', 'peanuts', 'neighborhood', 'possible', 'perfectly', 'soon', 'sat', 'array', 'binge', 'terrible', 'offers', 'building', 'reason', 'charming', 'hardest', 'fav', 'wings', 'disrespected', 'hummus', 'restaraunt', 'night', 'website', 'read', 'downtown', 'courteous', 'grandmother', 'daily', 'rinse', 'shops', 'also', 'witnessed', 'fluffy', 'meats', 'expertconnisseur', 'combo', 'mesquite', 'bus', 'drastically', 'inside', 'havent', 'hand', 'fo', 'times', 'much', 'rings', 'human', 'gold', 'killer', 'breakfast', 'amount', 'piece', 'stepped', 'bussell', 'perfection', 'getting', 'spicy', 'melt', 'dish', 'angry', 'hate', '2007', 'means', 'neither', 'ramseys', 'dressing', 'clue', 'interior', 'mayo', 'mmmm', 'drunk', 'doubt', 'especially', 'let', 'excalibur', 'wide', 'gotten', 'workingeating', 'prompt', 'trippy', 'undercooked', 'boba', 'thin', 'sucked', 'coupons', 'difference', 'stomach', 'hiro', 'nyc', 'end', 'brownish', 'older', 'location', 'google', 'bellagio', 'puréed', 'untoasted', 'sample', 'basically', 'outstanding', 'drinking', 'butter', 'multigrain', 'reminds', 'refried', 'airport', '1', 'wed', 'saganaki', 'breakfastlunch', 'completely', 'arepas', 'company', 'wines', 'easily', 'mediocre', 'ordering', 'another', 'batter', 'con', 'clean', 'vinaigrette', 'happy', 'pho', 'know', 'twice', 'decide', 'rice', 'personally', 'red', 'grease', 'shall', 'extra', 'editing', 'fell', 'employee', 'noodles', 'bad', 'ganoush', 'original', 'southwest', 'constructed', 'best', 'mean', 'glance', 'seated', 'strangers', 'han', 'loving', 'man', 'use', 'based', 'employees', 'great', 'decor', 'short', 'crusty', 'sun', 'chef', 'buying', 'figured', 'cash', 'girlfriends', 'profiterole', 'everything', 'enjoyable', 'happened', 'dark', 'acknowledged', 'avocado', 'pricey', 'regular', 'scene', 'despite', 'wall', 'auju', 'cafe', 'see', 'ago', 'satifying', 'second', 'dishes', 'desserts', 'family', 'delight', 'boyfriend', 'us', 'gem', 'cheeseburger', 'veal', 'dripping', 'excuse', 'omelets', 'leaves', 'care', 'join', 'baklava', 'plater', 'bamboo', 'wont', 'tender', 'strings', 'bug', 'lunch', 'lovely', 'ryans', 'incredible', 'chip', 'efficient', 'afternoon', 'flavors', 'crab', 'finger', '45', 'dreamed', 'done', 'bunch', 'charged', 'however', 'friendly', 'impressed', 'rich', 'phoenix', 'ignore', 'delicioso', 'three', 'case', 'calligraphy', 'crowd', 'lawyers', 'anticipated', 'review', 'interesting', 'music', 'elegantly', 'dirt', 'outside', 'bargain', 'honor', 'lots', 'soooo', 'pub', 'gyro', 'pats', 'salt', 'sense', 'teeth', 'sprouts', 'edible', 'reduction', 'drink', 'crowds', 'needed', 'crumby', 'think', 'ambience', 'discount', 'delights', 'kitchen', 'including', 'waiter', 'busy', 'corporation', 'vibe', 'beensteppedinandtrackedeverywhere', 'mango', 'desired', 'amazing', 'leave', 'absolutely', 'small', 'bouchon', 'mellow', 'everyone', 'section', 'fact', 'combination', 'perfect', 'teamwork', 'could', 'mediterranean', 'warmer', 'fine', 'spaghetti', 'english', 'allergy', 'old', 'deliciously', 'cart', 'japanese', 'establishment', 'poor', 'quite', 'bakery', 'styrofoam', 'relocated', 'café', 'fan', 'legit', 'turkey', 'correct', 'shrimp', 'youd', 'wouldnt', 'offered', 'rarely', 'hole', 'middle', 'would', 'course', 'limited', 'attack', 'ensued', 'gross', 'silently', 'bottom', 'go', 'unreal', 'always', 'week', 'fails', 'mojitos', 'cheek', 'colder', 'side', 'mussels', 'vegetables', 'hooked', 'generic', 'highquality', 'come', 'overall', 'youre', 'guacamole', 'dude', 'cashew', 'mess', 'strip', 'negligent', 'vegetarian', 'article', 'cost', 'hands', 'overwhelm', 'single', 'bites', 'send', 'lettuce', 'drag', 'picture', 'weve', 'atmosphere', 'needless', 'die', 'businesses', 'rick', 'exceeding', 'beans', 'bacon', 'restaurants', 'fare', 'tolerance', 'puree', 'melted', 'staff', 'ladies', 'spend', 'damn', 'bye', 'wasnt', 'sure', 'servers', 'boring', 'famous', 'usual', 'lost', 'stood', 'say', 'set', 'reasons', 'healthy', 'ownerchef', 'sauces', 'tacos', 'hello', 'customer', '100', 'served', 'frenchman', 'ms', 'ribeye', 'bowl', 'filling', 'main', 'couples', 'fella', 'stuff', 'upway', 'uploaded', 'indoor', 'enjoy', 'priced', 'two', 'pay', 'latte', 'plate', 'bank', 'lacked', 'choux', 'bean', 'dates', 'caring', 'dos', 'smoothies', 'town', 'mind', 'awesome', '4', 'found', 'lastly', 'eggs', 'dennys', 'overpriced', 'please', 'guess', 'want', 'spot', 'wrap', 'bone', 'magic', 'sandwich', 'crostini', 'crispy', 'chocolate', 'good', 'taste', 'six', 'hour', 'reviewing', 'told', 'trying', 'cooked', 'fish', 'soup', 'hope', 'heard', 'reviews', 'accordingly', 'places', 'tomato', 'highlighted', 'cover', 'deliver', 'different', 'maine', 'craving', 'familiar', 'fries', 'pineapple', 'actually', 'tuna', 'pile', 'spends', 'otherwise', 'stuffed', 'changing', 'risotto', 'date', 'flatlined', 'need', 'service', 'cakes', 'services', 'waitresses', 'holiday', 'chipolte', 'informative', 'awkwardly', 'double', 'loved', 'honeslty', 'reminded', 'known', 'visit', 'live', 'youll', 'legs', 'whether', 'recall', 'worries', 'seemed', 'corn', 'crema', 'unwelcome', 'quick', 'exceptional', 'groups', 'herewhat', 'restaurant', 'assure', 'mortified', 'fried', 'equally', 'soooooo', 'croutons', 'ethic', 'looking', 'pretty', 'plantains', 'ways', 'garlic', 'fry', 'like', 'bellies', 'ambiance', 'must', 'yet', 'word', 'paid', 'feel', 'authentic', 'enough', 'whatsoever', 'brushfire', 'beautiful', 'roast', 'updatewent', 'count', 'attentive', 'greens', 'biscuits', 'lobster', 'lil', 'wine', 'rave', 'hawaiian', 'tea', 'disgusted', 'raspberry', 'waitress', 'mouthful', 'sashimi', 'las', 'mid', 'wayyy', 'fear', 'hardly', 'manager', 'eaten', 'person', 'unhealthy', 'piano', 'ala', 'strange', 'left', 'towards', 'moist', 'returned', 'recommended', 'green', 'greatest', 'although', 'grab', 'none', 'boy', 'def', 'guys', 'medium', 'tasteless', 'beyond', 'sour', 'gone', '35', 'delivery', 'showed', 'prices', 'owners', 'warm', 'ayce', 'rushed', 'actual', 'made', 'quit', 'relax', 'haunt', 'ended', 'sunday', 'pleasure', 'egg', 'things', 'incredibly', 'summary', 'handed', 'omg', 'rotating', 'inhouse', 'provides', 'theyre', 'level', 'cant', 'salad', 'price', 'bathrooms', 'hot', 'bartenders', 'late', 'complaints', 'bought', 'helpful', 'enjoyed', 'hi', 'forward', 'recommendation', 'light', 'eggplant', 'bathroom', 'ate', 'rolls', 'yummy', 'help', 'goldencrispy', 'tailored', 'ball', 'wait', 'drive', 'fiancé', 'list', 'reservation', 'menus', 'beers', 'flair', 'yum', 'toast', '70', 'lemon', 'area', 'serivce', 'heat', 'professional', 'circumstances', 'home', 'underservices', 'self', 'high', 'sals', 'apologize', 'surprise', 'driest', 'decided', 'contain', 'greasy', 'avoid', 'coconut', 'kids', 'tapas', 'hes', 'cream', 'military', 'wrong', 'surprised', 'ok', 'meet', 'wants', 'top', 'sugar', 'jeff', 'az', 'special', 'dough', 'words', 'gc', 'screwed', 'spice', 'many', 'tiramisu', 'tough', 'brick', 'grocery', 'accountant', 'biscuit', 'least', 'whole', 'moods', 'lukewarm', 'belly', 'lacking', 'forgetting', 'extensive', 'expectations', 'powdered', 'jerk', 'nude', 'signs', 'gave', 'fondue', 'says', 'etc', 'hit', 'anytime', 'kept', 'fast', 'struggle', 'poop', 'literally', 'appealing', 'tots', 'vegas', 'baba', 'table', 'horrible', 'palate', 'club', 'beautifully', 'sucks', 'tops', 'highly', 'thick', 'uninspired', 'eel', 'pros', 'server', 'day', 'due', 'bartender', 'problem', 'disgusting', 'min', 'cow', 'cannoli', 'helped', 'carbs', 'yukon', 'verge', 'stinks', 'expected', 'mushrooms', 'delicate', 'unbelievably', 'foot', 'impeccable', 'tepid', 'return', 'potatoes', 'yama', 'bars', 'deserves', 'iced', 'charge', 'selection', 'paper', 'phenomenal', 'steve', 'though', 'blanket', 'olives', 'tables', 'totally', 'roasted', 'martini', 'recently', 'one', 'bother', 'far', 'never', 'extremely', 'truly', 'low', 'past', 'vinegrette', 'fuzzy', 'calamari', 'simply', 'downside', 'last', 'bachi', 'certainly', 'slaw', 'play', 'heart', 'paying', 'proclaimed', 'palm', 'sauce', 'alone', 'sound', 'outshining', 'kind', 'focused', 'wow', 'stop', 'isnt', 'bill', 'ive', 'hungry', 'make', 'chai', 'seafood', 'oven', 'welcome', 'arrived', 'full', 'oysters', 'buffets', 'life', 'obviously', 'back', 'rowdy', 'dont', 'rate', 'imaginative', 'delish', 'got', 'way', 'item', 'pack', 'brunch', 'included', 'eating', 'milk', 'complain', 'waited', 'officially', 'hated', 'arent', 'thought', 'burger', 'moz', 'crawfish', 'feeling', 'thai', 'bagels', 'disappointment', 'chains', 'overhip', 'ri', 'smashburger', 'sore', 'lets', 'weekly', '10', 'ground', 'hair', 'crepe', '7', 'took', '30s', 'rolled', 'connoisseur', 'large', '2', '90', 'blow', 'caesar', 'mayowell', 'lighting', 'looks', 'owner', 'become', 'gourmet', 'long', 'potato', 'ninja', 'specials', 'hut', 'white', 'passed', 'boot', 'coming', 'satisfying', 'without', 'close', 'monster', 'public', 'pizza', 'smeared', 'somewhat', 'highlight', 'seasoned', 'worse', 'drenched', 'used', 'flavored', 'creamy', 'reading', 'warnings', 'steiners', 'touch', 'attached', 'beer', 'received', 'supposed', 'texture', 'frustrated', 'hoping', 'said', 'gyros', '12', 'hard', 'consistent', 'strike', 'dining', 'meat', '3', 'flower', 'average', 'burned', 'vanilla', 'house', '20', 'style', 'speedy', 'dealing', 'publicly', 'servicecheck', '15', 'went', 'halibut', 'sause', 'edinburgh', 'ample', 'ask', 'give', 'nearly', 'filet', 'party', 'evening', 'wienerschnitzel', 'dipping', 'beateous', 'parents', 'degree', 'mac', 'glad', 'ripped', 'neat', 'traditional', 'awful', 'opinion', 'talking', '40min', 'mood', 'years', 'rock', 'lived', 'arriving', 'par', 'chipotle', 'star', 'moms', 'drinks'}\n",
            "The count feature of train data\n",
            "     chinese  andddd  785  steak  leftover  ...  par  chipotle  star  moms  drinks\n",
            "0          0       0    0      0         0  ...    0         0     0     0       0\n",
            "1          0       0    0      0         0  ...    0         0     0     0       0\n",
            "2          1       0    0      0         0  ...    0         0     0     0       0\n",
            "3          0       0    0      0         0  ...    0         0     0     0       0\n",
            "4          0       0    0      0         0  ...    0         0     0     0       0\n",
            "..       ...     ...  ...    ...       ...  ...  ...       ...   ...   ...     ...\n",
            "695        0       0    0      0         0  ...    0         0     0     0       0\n",
            "696        0       0    0      0         0  ...    0         0     0     0       0\n",
            "697        0       0    0      0         0  ...    0         0     0     0       0\n",
            "698        0       0    0      0         0  ...    0         0     0     0       0\n",
            "699        0       0    0      0         0  ...    0         0     0     0       0\n",
            "\n",
            "[700 rows x 1570 columns]\n",
            "The count feature of test data\n",
            "     chinese  andddd  785  steak  leftover  ...  par  chipotle  star  moms  drinks\n",
            "0          0       0    0      0         0  ...    0         0     0     0       0\n",
            "1          0       0    0      0         0  ...    0         0     0     0       0\n",
            "2          0       0    0      0         0  ...    0         0     0     0       1\n",
            "3          0       0    0      0         0  ...    0         0     0     0       0\n",
            "4          0       0    0      0         0  ...    0         0     0     0       0\n",
            "..       ...     ...  ...    ...       ...  ...  ...       ...   ...   ...     ...\n",
            "295        0       0    0      0         0  ...    0         0     0     0       0\n",
            "296        0       0    0      0         0  ...    0         0     0     0       0\n",
            "297        0       0    0      0         0  ...    0         0     0     0       0\n",
            "298        0       0    0      0         0  ...    0         0     0     0       0\n",
            "299        0       0    0      0         0  ...    0         0     0     0       0\n",
            "\n",
            "[300 rows x 1570 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NbpymZkg1IRq"
      },
      "source": [
        "### **Question 2d**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4jKNPiBayyVt"
      },
      "source": [
        "def Question2d(count_feature_train, count_feature_test, y_train):\n",
        "  MNB_Model = MultinomialNB(alpha = 1.0)\n",
        "  MNB_Model.fit(count_feature_train, y_train)\n",
        "  pred_train = MNB_Model.predict(count_feature_train)\n",
        "  pred_test = MNB_Model.predict(count_feature_test)\n",
        "  return pred_train, pred_test\n",
        "\n",
        "pred_train, pred_test = Question2d(count_feature_train, count_feature_test, y_train)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cxlZq8yB1MoC"
      },
      "source": [
        "### **Question 2e**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e_L4J4Q28ZTH",
        "outputId": "bba23fcc-f112-4236-cc50-8661ba74f6fd"
      },
      "source": [
        "def Question2e(y_train, pred_train, y_test, pred_test,X_train,X_test):\n",
        "  #Finding accuracy\n",
        "  acc_train = accuracy_score(y_train,pred_train)\n",
        "  acc_test = accuracy_score(y_test,pred_test)\n",
        "  print(\"The Train Accuracy is \", acc_train)\n",
        "  print(\"The Validation' Accuracy is \", acc_test)\n",
        "  X_train = X_train.reset_index(drop = True)\n",
        "  y_train = y_train.reset_index(drop = True)\n",
        "  X_test = X_test.reset_index(drop = True)\n",
        "  y_test = y_test.reset_index(drop = True)\n",
        "  num_train = 5\n",
        "  num_test = 5\n",
        "  #Finding the misclassified train labels\n",
        "  print(\"\\nMisclassified Train labels\")\n",
        "  for i in range(y_train.shape[0]):\n",
        "    if(y_train[i] != pred_train[i] and num_train>0):\n",
        "      print(X_train.iloc[i], y_train[i])\n",
        "      num_train -= 1\n",
        "\n",
        "  print(\"\\nMisclassified Test labels\")\n",
        "  #Finding the misclassified test labels\n",
        "  for i in range(y_test.shape[0]):\n",
        "    if(y_test[i] != pred_test[i] and num_test>0):\n",
        "      print(X_test.iloc[i], y_test[i])\n",
        "      num_test -= 1\n",
        "Question2e(y_train, pred_train, y_test, pred_test,X_train,X_test)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The Train Accuracy is  0.96\n",
            "The Validation' Accuracy is  0.7833333333333333\n",
            "\n",
            "Misclassified Train labels\n",
            "['dont', 'many', 'words', 'say', 'place', 'everything', 'pretty', 'well'] 1\n",
            "['promise', 'wont', 'disappoint'] 1\n",
            "['overall', 'like', 'place', 'lot'] 1\n",
            "['ill', 'definitely', 'soon'] 1\n",
            "['much', 'better', 'ayce', 'sushi', 'place', 'went', 'vegas'] 1\n",
            "\n",
            "Misclassified Test labels\n",
            "['would', 'recommend', 'others'] 0\n",
            "['came', 'running', 'us', 'realized', 'husband', 'left', 'sunglasses', 'table'] 1\n",
            "['good', 'stretch', 'imagination'] 0\n",
            "['redeeming', 'quality', 'restaurant', 'inexpensive'] 1\n",
            "['dont', 'much', 'pasta', 'love', 'homemade', 'hand', 'made', 'pastas', 'thin', 'pizzas'] 1\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}